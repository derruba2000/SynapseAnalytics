{"cells":[{"cell_type":"markdown","source":["## Model training and registration\n\nThis notebook shows the process for training the model, converting the model to ONNX and uploading the ONNX model to Azure Storage."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d7be1f8d-cd7a-406f-b080-af4fa1309542"}}},{"cell_type":"markdown","source":["### Mount Azure storage accounts in Azure Databricks\n\nWe will use `dbutils` to mount the remote Azure storage accounts as local DBFS folders.\n\nOnce we do that we'll be able to read/write directly from/to Azure storage.\n\n>**IMPORTANT!**\n>In the code below, perform the following replacements:\n>- Replace `<data_storage_account_name>` with the name of the Data Lake storage account (has the `asadatalakeNNNNNN` form).\n>- Replace `<data_storage_account_key>` with the access key associated to the Data Lake storage account.\n>- Replace `<model_storage_account_name>` with the name of the blob storage account (has the `asastoreNNNNNN` form).\n>- Replace `<model_storage_account_key>` with the access key associated to the blob storage account."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"aacd2619-b435-468c-8723-a41f7f6715af"}}},{"cell_type":"code","source":["data_storage_account_name = '<data_storage_account_name>'\ndata_storage_account_key = '<data_storage_account_key>'\nmodel_storage_account_name = '<model_storage_account_name>'\nmodel_storage_account_key = '<model_storage_account_key>'\n\ndata_mount_point = '/mnt/data'\nmodel_mount_point = '/mnt/model'\n\ndata_file_path = '/bronze/wwi-factsale.csv'\nmodel_file_path = '/onnx/model.onnx'\n\ndbutils.fs.mount(\n  source = f\"wasbs://dev@{data_storage_account_name}.blob.core.windows.net\",\n  mount_point = data_mount_point,\n  extra_configs = {f\"fs.azure.account.key.{data_storage_account_name}.blob.core.windows.net\": data_storage_account_key})\n\ndbutils.fs.mount(\n  source = f\"wasbs://models@{model_storage_account_name}.blob.core.windows.net\",\n  mount_point = model_mount_point,\n  extra_configs = {f\"fs.azure.account.key.{model_storage_account_name}.blob.core.windows.net\": model_storage_account_key})"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c6805db1-f8f1-4273-9307-1855c9d4de73"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Test the data mount point."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"06533df9-c2b1-4d1c-bced-e56a42fd817b"}}},{"cell_type":"code","source":["dbutils.fs.ls(f'{data_mount_point}/bronze')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a3fd50ba-6521-4be9-aa6a-f67f377e2fbc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Test the model mount point."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7aa23c21-7d26-4469-b003-9468f5152d65"}}},{"cell_type":"code","source":["dbutils.fs.ls(f'{model_mount_point}')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"86e6803a-5bd7-4ab0-86e2-e48dd0b61e8c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Explore the training data\n\nThe following cells load the source CSV file into a Spark DataFrame and create a temporary view that can be used to query the data with Spark SQL."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7397940f-79e2-4d6b-bb49-a18ec6307040"}}},{"cell_type":"code","source":["from pyspark.sql.functions import col\ndf = spark.read.load(f'{data_mount_point}/{data_file_path}', format=\"csv\", header=True, sep=\"|\")\n\ndf.createOrReplaceTempView(\"facts\")\ndisplay(spark.sql(\"SELECT * FROM facts WHERE `Customer Key` == '11' ORDER BY `Stock Item Key`\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"51c2206f-afa3-404f-aa44-c20a86995058"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["You may also query your table via SQL"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a5040414-4ede-4883-b3af-a9968fe11ac9"}}},{"cell_type":"code","source":["%sql\n\nSELECT * FROM facts LIMIT 100;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9e900758-cdfe-42e8-be63-c1f13841b9f8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Predict Quantity given Customer Key and Stock Item Key\n\nIn the following cells we load a subset of the data that contains only the fields needed for training."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d98214b4-a5e0-4d80-8827-77c3bae7e468"}}},{"cell_type":"code","source":["df3 = spark.sql(\"SELECT double(`Customer Key`) as customerkey, double(`Stock Item Key`) as stockitemkey, double(`Quantity`) as quantity FROM facts\").where(col(\"quantity\").isNotNull())\ndf3.cache()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e66eebb4-92dd-4d45-9ad2-2f8cfc1d2f38"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Next, we package the data into the format expected by Spark ML's `LinearRegression`. \n\nIt requires a DataFrame with two columns: `features` and a column with the labels to predict (`quantity` in this case)."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fd777280-5253-4c43-846e-0b1df5e9e119"}}},{"cell_type":"code","source":["#package the data into the format expected by Spark ML's LinearRegression. It requires a DataFrame with two columns: features and a column with the labels to predict (quantity in this case)\nfrom pyspark.ml.feature import VectorAssembler\n\nvectorAssembler = VectorAssembler(inputCols = ['customerkey', 'stockitemkey'], outputCol = 'features')\ndf4 = vectorAssembler.transform(df3)\ndf5 = df4.select(['features', 'quantity'])\ndf5.show(10)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"39853711-022a-461b-9f88-037fdac3a665"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Now, we split our DataFrame into training and testing DataFrames."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0682ddaf-f505-4582-be56-76a7febbdc28"}}},{"cell_type":"code","source":["trainingFraction = 0.7\ntestingFraction = (1 - trainingFraction)\nseed = 42\ndf_train, df_test = df5.randomSplit([trainingFraction, testingFraction], seed=seed)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"84bf79eb-3aef-47c2-af55-304fd6901edc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["In the following cell, we train our `LinearRegression` model."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b27c8a07-df20-4710-9df2-9ef2551d22b8"}}},{"cell_type":"code","source":["from pyspark.ml.regression import LinearRegression\n\nlin_reg = LinearRegression(featuresCol = 'features', labelCol='quantity', maxIter = 10, regParam=0.3)\nlin_reg_model = lin_reg.fit(df_train)\nprint(\"Coefficients: \" + str(lin_reg_model.coefficients))\nprint(\"Intercept: \" + str(lin_reg_model.intercept))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6a2e0a8b-eb56-4d7f-9d1b-b187a393897d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["With a trained model in hand, we can use it to make predictions against the test DataFrame."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c04646da-a92f-4ce5-b3b6-09eaf82b6dd3"}}},{"cell_type":"code","source":["df_pred = lin_reg_model.transform(df_test)\ndisplay(df_pred)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"53b9ef80-8c13-4d5f-8337-917ea50c4c47"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Convert model to ONNX format\n\nIn the cells that follow, we convert the model to ONNX and show how an output of how ONNX represents the Spark ML model."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"626f6df7-d23c-4dd8-9760-4eb0bc013f9f"}}},{"cell_type":"code","source":["from onnxmltools import convert_sparkml\nfrom onnxmltools.convert.common.data_types import FloatTensorType\n\ninitial_types = [ \n    (\"features\", FloatTensorType([1, lin_reg_model.numFeatures])),\n    # (repeat for the required inputs)\n]\n\nmodel_onnx = convert_sparkml(lin_reg_model, 'sparkml GeneralizedLinearRegression', initial_types)\nmodel_onnx"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bedf534b-5495-4294-8c85-dc7a8bc29949"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Upload the model to Azure Storage\n\nTo upload the ONNX model to Azure Storage we can use the locally mounted folder."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6131865b-0916-4003-af80-403473db4436"}}},{"cell_type":"code","source":["contents = model_onnx.SerializeToString()\nprint(contents)\n\nf=open(\"/dbfs/tmp/model.onnx\", \"wb\") \nf.write(contents)\nf.close()\ndbutils.fs.cp(\"dbfs:/tmp/model.onnx\", f'{model_mount_point}{model_file_path}')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4cda7bed-b6f4-4195-b353-676402661fa5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["As a last step we browse the mounted folder to verify the presence of the ONNX model on the remote storage."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6f64b24d-433b-4a19-9249-38abe38abdc3"}}},{"cell_type":"code","source":["dbutils.fs.ls(f'{model_mount_point}/onnx')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a2778249-c4e5-4749-aaf2-93cee41f453a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Exercise 5 - Model Training.dbc","dashboards":[{"elements":[{"elementNUID":"51c2206f-afa3-404f-aa44-c20a86995058","guid":"6443a0d1-e2d4-43d5-946a-182450e173a7","options":null,"position":{"x":0,"y":6,"height":6,"width":12,"z":null},"elementType":"command"},{"elementNUID":"9e900758-cdfe-42e8-be63-c1f13841b9f8","guid":"813cb524-e90c-49a7-95f6-e13414d83f0b","options":null,"position":{"x":0,"y":12,"height":6,"width":12,"z":null},"elementType":"command"},{"elementNUID":"a2778249-c4e5-4749-aaf2-93cee41f453a","guid":"a93565b8-3e13-4a46-ae0c-27e5211c2284","options":null,"position":{"x":0,"y":24,"height":6,"width":12,"z":null},"elementType":"command"},{"elementNUID":"e66eebb4-92dd-4d45-9ad2-2f8cfc1d2f38","guid":"eb76f739-397e-4f5c-b79d-268e46358d65","options":null,"position":{"x":0,"y":18,"height":6,"width":12,"z":null},"elementType":"command"}],"guid":"b91a0a31-b724-4de7-bf0e-46d75e589828","layoutOption":{"stack":true,"grid":true},"version":"DashboardViewV1","nuid":"86a7c823-c74d-4827-85a1-b47d78dc6c81","origId":2730881319457921,"title":"Untitled","width":1024,"globalVars":{}}],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":2730881319457893}},"nbformat":4,"nbformat_minor":0}
